---
title: "Meeting 8 - Review of Central Limit Theorem and Confidence Intervals"
author: "Matthew E. Aiello-Lammens"
date: '2020-03-25'
output:
  html_document:
    code_folding: hide
    toc: yes
---

# Today's Goals

* Review the Central Limit Theorem
* Introduce principles of hypothesis testing

***

# Standard Normal distribution

Recall that last week we were introduced to the Normal (or Gaussian) Distribution with pdf:

$$
f(x|\mu,\sigma) \sim \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$

The **Standard Normal** distribution is a **Normal** distribution with $\mu = 0$ and $\sigma = 1$.


### Z-scores

As noted last class, we can convert from a normal distribution with any mean $\mu$ and standard deviation $\sigma$ to the standard normal by subtracting the mean from each value, then dividing by the standard deviation:

$$
z_i = \frac{y_i - \mu}{\sigma}
$$

The resulting values of this conversation are more commonly referred to as **Z-scores**.

**The z-score $z_i$ associated with the data point $y_i$ represents how many units of standard deviation $y_i$ is away from the mean of the distribution.**


***

# The Central Limit Theorem

## Sampling distribution of the mean

The frequency distribution of the **mean values** of several *different samples* taken from a population.

From Q&K p. 18:

> The probability distribution of means of samples from a normal distribution is also normally distributed.

## Using the CLT

From Q&K p. 18:

> The expected value or mean of the probability distribution of sample means equals the mean of the population ($\mu$) from which the samples were taken.


### Standard error of the sample mean

Last week we saw that **sample means are normally distributed**. 
What can we do with this?
To start, we can say something about the precision and accuracy of our estimates of the *population* mean based on the *sample* mean.

**Standard error of the mean** - the expected value of the standard deviation of the sample mean:

$$
\sigma_{\bar{y}} = \frac{\sigma}{\sqrt{n}}
$$

Often times we only have **one sample** from the population. What can we say then?

Standard error of the mean:

$$
s_{\bar{y}} = \frac{s}{\sqrt{n}}
$$

where $s$ is the sample estimate of the standard deviation of the original population and $n$ is the sample size.

**NB:** The standard error of the means "tells us about the error in using $\bar{y}$ to estimate $\mu$."


## Confidence intervals for the population mean

Recall that we can convert any observation from normal distribution to it's equivalent value from a standard normal distribution using:

$$
z_i = \frac{y_i - \mu}{\sigma}
$$

and that these are sometimes called ***z-scores***.

Using this formula, we can convert a sample mean, $\bar{y}$, into its corresponding value from a standard normal using:

$$
z = \frac{\bar{y} - \mu}{\sigma_{\bar{y}}}
$$

where the denominator is the standard error of the mean (see above). 

We can use this information to estimate how confident we are that are sample mean is a good representation of the *true* population mean.
Again, we are doing this by taking advantage of the fact that we know the sample means are *normally distributed*.
We calculate the range in which 95% of the sample mean values fall.

In mathematical terms, this looks like:

$$
P\{\bar{y} - 1.96\sigma_{\bar{y}} \leq \mu \leq \bar{y} + 1.96\sigma_{\bar{y}} \} = 0.95
$$

**VERY IMPORTANT:** The probability statement here is about the *interval*, not $\mu$. 
$\mu$ is not a random variable; it is fixed.
What we are saying is that there is 95% confidence that this interval includes the population mean, $\mu$.



### Unknown $\sigma$ (and $\sigma_{\bar{y}}$)

We rarely know $\sigma$, so we cannot calculate $\sigma_{\bar{y}}$. 
So what *can* we do?

Instead, we use the sample standard deviation, $s_{\bar{y}}$. 
So now we are dealing with a random variable that looks like: 

$$
\frac{\bar{y}-\mu}{s_{\bar{y}}}
$$

which is no longer standard normal distributed, but rather ***t* distributed**.

#### Challenge

Use whatever resource available to you, and look-up the ***t* distribution**.
What is/are the parameter(s) of the *t* distribution?


### Degrees of freedom

> The number of observations in our sample that are "free to vary" when we are estimating the variance (Q&K p.20; Box 2.1).

If I have calculated the mean, how many observations, out of a total of *n*, are free to vary?

**Answer:** $n-1$. Once I have the mean, I can use it and any $n-1$ values to calculate the *n*th value.

General rule regarding df's:

> the df is the number of observations minus the number of parameters included in the formula for the variance (Q&K p.20; Box 2.1).

## Example of working with Confidence Intervals in R

I've worked out a full example of working with confidence intervals [here](http://mlammens.github.io/ENS-623-Research-Stats/lectures/Lecture-8-1-Confidence-Intervals.html). Please have a look.


## Standard error of other statistics

> The standard error is ... the standard deviation of the probability distribution of a specific statistics (Q&K p. 20).

### Standard error of the sample variance

The distribution of the sample variance is *not normal*. It is $\chi^2$ distributed.

Mathematically, this is explained as:

$$
X \sim N(0,1) \to X^2 \sim \chi^2
$$

Intuitively, why does this make sense?

***


