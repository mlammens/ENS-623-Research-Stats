---
title: "Meeting 8 - Confidence Interval Activity"
author: "Matthew Aiello-Lammens"
date: "2020-03-25"
output: html_document
---

## Learning Objectives

* Understand the relationship between population statistics, sample statistics, and confidence intervals
* Become familiar with how to calculate a margin of error and confidence interval
* Understand the use of confidence intervals in hypothesis testing

## Working with the Youth Risk Behavior Surveillance System (YRBSS) data

In this lesson, we're going to explore variation in point estimates and Confidence Intervals.
We will largely be following content that can be found in the textbook OpenIntro Statistics by Diez, Barr, and Ã‡etinkaya-Rundel, 3rd Edition (posted on Perusall).

As in Chapter 4 of the textbook, we'll be working with the Youth Risk Behavior Surveillance System (YRBSS).
You can find more information on these data at [https://www.cdc.gov/healthyyouth/data/yrbs/data.htm](https://www.cdc.gov/healthyyouth/data/yrbs/data.htm).
We will start be examining the **full** data set.

### Population Parameters

Let's begin by loading the data into our environment.

You may need to first install the `openintro` R package

```{r, eval=FALSE}
install.packages("openintro")
```

After that, we can load in the data.

```{r}
library(openintro)
data(yrbss)
?yrbss
```


As with any data set, let's have a quick look at the data using `summary`.

```{r}
summary(yrbss)
```

Let's also have a look at the first few rows, to get a sense for what some of these answers look like.

```{r}
head(yrbss)
```


For now, let's focus on the variable `height`. 
First, let's calculate the **population mean** for `height`.
Remember, that the population mean is going to be the mean value for the *full* data set.

```{r}
mean(yrbss$height)
```

That's probably not the answer you were expecting. 
There must have been students whose data was collected, but their heights weren't recorded, so a value of *NA* was assigned.
In order to ignore these data, we need to add the argument `na.rm = TRUE` to our `mean` call.

```{r}
mean(yrbss$height, na.rm = TRUE)
```

Let's save this as a new variable.

```{r}
yrbss_hgt_pop <- mean(yrbss$height, na.rm = TRUE)
```



### Sample Parameter Estimates

OK, let's assume that we could only collect data from a subset of the high school students whose data are in this data set. 
We can use the data in this subset to **estimate** population level parameters.
This subset is called our **sample**.

We'll choose a subset at random, but we'll make it so that everyone in the class gets the same random subset.

```{r}
set.seed(623)
yrbss_samp <- yrbss[sample(x = 1:nrow(yrbss), replace = FALSE, size = 10), ]
```

**Challenge:** Breakdown each piece of the command that we are using to get our sample.
To do this, you may want to look at the help for `sample`.

Let's calculate the mean height based on our sample.

```{r}
mean(yrbss_samp$height, na.rm = TRUE)
```

As we did with the population mean, let's save this as a new variable.

```{r}
yrbss_hgt_samp <- mean(yrbss_samp$height, na.rm = TRUE)
```

How does it compare to the true mean?

```{r}
yrbss_hgt_pop
yrbss_hgt_samp
yrbss_hgt_pop == yrbss_hgt_samp
```


Let's try increasing our sample size, and see if that makes a difference?

#### Sample size = 100

```{r}
set.seed(623)
yrbss_samp <- yrbss[sample(x = 1:nrow(yrbss), replace = FALSE, size = 100), ]
mean(yrbss_samp$height, na.rm = TRUE)
```

#### Sample size = 1000

```{r}
set.seed(623)
yrbss_samp <- yrbss[sample(x = 1:nrow(yrbss), replace = FALSE, size = 1000), ]
mean(yrbss_samp$height, na.rm = TRUE)
```


In general, though not always, as you increase sample size, you get closer to the *true* population values for an estimated parameter.


## Standard Error of the Mean

Let's imagine the we took 100 different subsets from these data, then calculated the mean for each of these subsets, and then examined the histogram of these means.
The shape of the histogram should prove to be that of a normal distribution.

In order to demonstrate this, we'll need to use `for` loops.


```{r}
# start with a vector to store our mean values
samp_means <- c()

# start a for loop the does 100 iterations
for(x in 1:100){
  # get a sample of the data of size 100
  yrbss_samp <- yrbss[sample(x = 1:nrow(yrbss), replace = FALSE, size = 100), ]
  
  # calulate the mean of this sample
  mean_samp <- mean(yrbss_samp$height, na.rm = TRUE)
  
  # add this mean to the vector of sample means
  samp_means <- c(samp_means, mean_samp)
}

```

We should now have 100 values in the vector `samp_means`. 
Let's look at a histogram of these values.

```{r}
library(ggplot2)

ggplot() +
  geom_histogram(aes(x = samp_means))
```


Alright, it's normalish (i.e., approximately normal), though clearly not perfectly normal.

**Challenge:** What is the mean of the means?

**Challenge:** What is the standard deviation of the means?

**Challenge:** How do the above to values compare to the population values?

```{r}
mean(yrbss$height, na.rm = TRUE)
mean(samp_means)
sd(yrbss$height, na.rm = TRUE)
sd(samp_means)

```

The means are very similar, but the sds are not. Why?


The **standard error of the mean** is the standard deviation of the *estimates*. 


In practice, we only examine *one*, or a very few, samples. We can still compute the standard error of the mean using the formula:

$$
SE = \frac{\sigma}{\sqrt{n}}
$$


, where $\sigma$ is the population standard deviation and $n$ is the sample size.

However we almost never know $\sigma$, so we estimate it with our **sample standard deviation** value.

Let's calculate the SE using the data from `yrbss_samp`.

```{r}
yrbss_samp_SE <- sd(yrbss_samp$height, na.rm = TRUE) / sqrt(nrow(yrbss_samp))
yrbss_samp_SE
```

Note how close `yrbss_samp_SE` and `sd(samp_means)` is!


## Confidence Intervals

We just demonstrated that **sample means are approximately normally distributed**. 
What can we do with this?
To start, we can say something about the precision and accuracy of our estimates of the *population* mean based on the *sample* mean.

Recall that we can convert any observation from normal distribution to it's equivalent value from a standard normal distribution using:

$$
z_i = \frac{y_i - \mu}{\sigma}
$$

These are sometimes called ***z-scores***.

Using this formula, we can convert a sample mean, $\bar{y}$, into its corresponding value from a standard normal using:

$$
z = \frac{\bar{y} - \mu}{SE}
$$

where the denominator is the standard error of the mean (see above). 

We can use this information to estimate how confident we are that are sample mean is a good representation of the *true* population mean.
Again, we are doing this by taking advantage of the fact that we know the sample means are *normally distributed*.
We calculate the range in which 95% of the sample mean values fall.

In mathematical terms, this looks like:

$$
P\{\bar{y} - 1.96 \times SE \leq \mu \leq \bar{y} + 1.96 \times  SE \} = 0.95
$$

**VERY IMPORTANT:** The probability statement here is about the *interval*, not $\mu$. 
$\mu$ is not a random variable; it is fixed.
What we are saying is that there is 95% confidence that this interval includes the population mean, $\mu$.



### Unknown $\sigma$ (and $SE$)

As noted above, we rarely know $\sigma$, so we cannot calculate $SE$ exactly. 
So what *can* we do?

Instead, we use the sample standard deviation, $s_{\bar{y}}$. 
So now we are dealing with a random variable that looks like: 

$$
\frac{\bar{y}-\mu}{SE}
$$

which is no longer standard normal distributed, but rather ***t* distributed**.
We'll learn more about this distribution later!

### Calculating Confidence Intervals

Let's calculate the Confidence Interval for our estimate of mean height, using our very first sample of the yrbss data.

First, get the sample again.

```{r}
set.seed(623)
yrbss_samp <- yrbss[sample(x = 1:nrow(yrbss), replace = FALSE, size = 10), ]
```

Calculate our sample means.

```{r}
yrbss_hgt_samp_mean <- mean(yrbss$height, na.rm = TRUE)
```


Now, let's calculate Standard Error.

```{r}
yrbss_hgt_samp_SE <- sd(yrbss_samp$height, na.rm = TRUE) / sqrt(nrow(yrbss_samp))
```

Now, calculate our 95% Confidence Interval.

```{r}
CI_yrbss_upper <- yrbss_hgt_samp_mean + (1.96*yrbss_hgt_samp_SE)
CI_yrbss_lower <- yrbss_hgt_samp_mean - (1.96*yrbss_hgt_samp_SE)
CI_yrbss_upper
CI_yrbss_lower
```

Does our Confidence Interval contain the *true* population mean?

**Challenge:** what happens to the Confidence Interval if you increase the sample size to 100?


# Examining multiple estimates and confidence intervals



```{r}
set.seed(623)

# start with vectors to store mean and upper / lower CI values
samp_means <- c()
samp_CI_Upper <- c()
samp_CI_Lower <- c()

# start a for loop the does 25 iterations
for(x in 1:25){
  # get a sample of the data of size 10
  yrbss_samp <- yrbss[sample(x = 1:nrow(yrbss), replace = FALSE, size = 10), ]
  
  # calculate the mean of this sample
  mean_samp <- mean(yrbss_samp$height, na.rm = TRUE)
  # add this mean to the vector of sample means
  samp_means <- c(samp_means, mean_samp)
  
  # calculate the upper and lower CI values
  se_samp <- sd(yrbss_samp$height, na.rm = TRUE) / sqrt(nrow(yrbss_samp))
  CI_upper <- mean_samp + (1.96*se_samp)
  CI_lower <- mean_samp - (1.96*se_samp)
  samp_CI_Upper <- c(samp_CI_Upper, CI_upper)
  samp_CI_Lower <- c(samp_CI_Lower, CI_lower)
  
}

```

Now let's build a plot that compared the sample means and confidence intervals to the true population mean

```{r}
samp_stats_df <- data.frame(obs = 1:length(samp_means), samp_means = samp_means, samp_CI_Lower = samp_CI_Lower, samp_CI_Upper = samp_CI_Upper)

ggplot(data = samp_stats_df) + 
  geom_point(aes(x = samp_means, y = obs)) +
  geom_linerange(aes(xmin = samp_CI_Lower, xmax = samp_CI_Upper, y = obs)) +
  geom_vline(xintercept = yrbss_hgt_pop, color = "red") + 
  theme_bw()
```



